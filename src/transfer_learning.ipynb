{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "import utils\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Recreate vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../dataset/tweets/tweets_emotion_6/emotion_6-processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_DIST_FILE = '../dataset/tweets/tweets_polarity_2/tweets_pos_neg_train-processed-freqdist.pkl'\n",
    "GLOVE_FILE = '../dataset/embedding/glove-seeds.txt'\n",
    "dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "np.random.seed(1337)\n",
    "vocab_size = 90000\n",
    "max_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the original vocab\n",
    "vocab = utils.top_n_words(FREQ_DIST_FILE, vocab_size, shift=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Preprocess Emotion 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(tweet):\n",
    "    \"\"\"\n",
    "    Generates a feature vector for each tweet where each word is\n",
    "    represented by integer index based on rank in vocabulary.\n",
    "    \"\"\"\n",
    "    words = tweet.split()\n",
    "    feature_vector = []\n",
    "    for i in range(len(words) - 1):\n",
    "        word = words[i]\n",
    "        if vocab.get(word) is not None:\n",
    "            feature_vector.append(vocab.get(word))\n",
    "    if len(words) >= 1:\n",
    "        if vocab.get(words[-1]) is not None:\n",
    "            feature_vector.append(vocab.get(words[-1]))\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def process_tweets(csv_file, test_file=True):\n",
    "    \"\"\"\n",
    "    Generates training X, y pairs.\n",
    "    \"\"\"\n",
    "    tweets = []\n",
    "    labels = []\n",
    "    print('Generating feature vectors')\n",
    "    with open(csv_file, 'r') as csv:\n",
    "        lines = csv.readlines()\n",
    "        total = len(lines)\n",
    "        for i, line in enumerate(lines):\n",
    "            if test_file:\n",
    "                tweet_id, tweet = line.split(',')\n",
    "            else:\n",
    "                tweet_id, sentiment, tweet = line.split(',')\n",
    "            feature_vector = get_feature_vector(tweet)\n",
    "            if test_file:\n",
    "                tweets.append(feature_vector)\n",
    "            else:\n",
    "                tweets.append(feature_vector)\n",
    "                labels.append(int(sentiment))\n",
    "            utils.write_status(i + 1, total)\n",
    "    print('\\n')\n",
    "    return tweets, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EMOTION_6 = '../dataset/tweets/tweets_emotion_6/emotion_6-processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 383456/416809rocessing 63344/416809Processing 159124/416809Processing 161323/416809Processing 184718/416809Processing 226293/416809Processing 276463/416809Processing 309057/416809Processing 325654/416809Processing 374031/416809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 387310/416809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 398018/416809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 409334/416809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 411699/416809"
     ]
    }
   ],
   "source": [
    "tweets_emo_6, labels_emo_6 = process_tweets(TRAIN_EMOTION_6, test_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_emo_6 = to_categorical(labels_emo_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_emo_6 = pad_sequences(tweets_emo_6, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(tweets_emo_6.shape[0])\n",
    "tweets_emo_6 = tweets_emo_6[shuffled_indices]\n",
    "labels_emo_6 = labels_emo_6[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Preprocess Emotion 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EMOTION_4 = '../dataset/tweets/tweets_emotion_4/tweets_emotions_train-processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 6005/30160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10426/30160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 15558/30160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 19384/30160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 23300/30160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 27427/30160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30160/30160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_emo_4, labels_emo_4 = process_tweets(TRAIN_EMOTION_4, test_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_emo_4 = to_categorical(labels_emo_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_emo_4 = pad_sequences(tweets_emo_4, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(tweets_emo_4.shape[0])\n",
    "tweets_emo_4 = tweets_emo_4[shuffled_indices]\n",
    "labels_emo_4 = labels_emo_4[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transfer learning - (polarity_2 to emotion_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load model (positive/negative CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "PATH_MODEL_POS_NEG = '../models/base_model/4cnn-04-0.342-0.851-0.389-0.828.hdf5'\n",
    "transfer_model = load_model(PATH_MODEL_POS_NEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 200)           18000200  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 38, 600)           360600    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 36, 300)           540300    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 34, 150)           135150    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 32, 75)            33825     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               1440600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 601       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 20,511,276\n",
      "Trainable params: 20,511,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut last layers\n",
    "transfer_model.pop()\n",
    "transfer_model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers\n",
    "for layer in transfer_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add news layers\n",
    "transfer_model.add(Dense(400, name='dense_2'))\n",
    "transfer_model.add(Activation('relu', name='activation_2'))\n",
    "\n",
    "transfer_model.add(Dense(6, name='dense_3'))\n",
    "transfer_model.add(Activation('softmax', name='activation_3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Fine tunning and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "#adam = optimizers.Adam(lr=5)\n",
    "transfer_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 200)           18000200  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 38, 600)           360600    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 36, 300)           540300    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 34, 150)           135150    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 32, 75)            33825     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               1440600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 2406      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 20,753,481\n",
      "Trainable params: 242,806\n",
      "Non-trainable params: 20,510,675\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./transfer_pol2_emo6/entire_corpus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "filepath = \"./transfer_pol2_emo6/entire_corpus/{epoch:02d}-{loss:0.3f}-{acc:0.3f}-{val_loss:0.3f}-{val_acc:0.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 375128 samples, validate on 41681 samples\n",
      "Epoch 1/20\n",
      "375128/375128 [==============================] - 388s 1ms/step - loss: 1.3640 - acc: 0.5028 - val_loss: 1.3349 - val_acc: 0.5098\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.36396, saving model to ./transfer_pol2_emo6/entire_corpus/01-1.364-0.503-1.335-0.510.hdf5\n",
      "Epoch 2/20\n",
      "375128/375128 [==============================] - 353s 941us/step - loss: 1.3475 - acc: 0.5069 - val_loss: 1.3285 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00002: loss improved from 1.36396 to 1.34755, saving model to ./transfer_pol2_emo6/entire_corpus/02-1.348-0.507-1.328-0.511.hdf5\n",
      "Epoch 3/20\n",
      "375128/375128 [==============================] - 349s 930us/step - loss: 1.3438 - acc: 0.5078 - val_loss: 1.3226 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00003: loss improved from 1.34755 to 1.34383, saving model to ./transfer_pol2_emo6/entire_corpus/03-1.344-0.508-1.323-0.512.hdf5\n",
      "Epoch 4/20\n",
      "375128/375128 [==============================] - 353s 942us/step - loss: 1.3408 - acc: 0.5087 - val_loss: 1.3197 - val_acc: 0.5139\n",
      "\n",
      "Epoch 00004: loss improved from 1.34383 to 1.34083, saving model to ./transfer_pol2_emo6/entire_corpus/04-1.341-0.509-1.320-0.514.hdf5\n",
      "Epoch 5/20\n",
      "375128/375128 [==============================] - 349s 930us/step - loss: 1.3391 - acc: 0.5096 - val_loss: 1.3182 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00005: loss improved from 1.34083 to 1.33906, saving model to ./transfer_pol2_emo6/entire_corpus/05-1.339-0.510-1.318-0.514.hdf5\n",
      "Epoch 6/20\n",
      "375128/375128 [==============================] - 350s 933us/step - loss: 1.3379 - acc: 0.5098 - val_loss: 1.3175 - val_acc: 0.5143\n",
      "\n",
      "Epoch 00006: loss improved from 1.33906 to 1.33789, saving model to ./transfer_pol2_emo6/entire_corpus/06-1.338-0.510-1.317-0.514.hdf5\n",
      "Epoch 7/20\n",
      "375128/375128 [==============================] - 361s 962us/step - loss: 1.3361 - acc: 0.5103 - val_loss: 1.3158 - val_acc: 0.5146\n",
      "\n",
      "Epoch 00007: loss improved from 1.33789 to 1.33608, saving model to ./transfer_pol2_emo6/entire_corpus/07-1.336-0.510-1.316-0.515.hdf5\n",
      "Epoch 8/20\n",
      "375128/375128 [==============================] - 349s 932us/step - loss: 1.3352 - acc: 0.5105 - val_loss: 1.3156 - val_acc: 0.5136\n",
      "\n",
      "Epoch 00008: loss improved from 1.33608 to 1.33516, saving model to ./transfer_pol2_emo6/entire_corpus/08-1.335-0.511-1.316-0.514.hdf5\n",
      "Epoch 9/20\n",
      "375128/375128 [==============================] - 348s 927us/step - loss: 1.3347 - acc: 0.5104 - val_loss: 1.3127 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00009: loss improved from 1.33516 to 1.33471, saving model to ./transfer_pol2_emo6/entire_corpus/09-1.335-0.510-1.313-0.515.hdf5\n",
      "Epoch 10/20\n",
      "375128/375128 [==============================] - 346s 923us/step - loss: 1.3336 - acc: 0.5107 - val_loss: 1.3126 - val_acc: 0.5154\n",
      "\n",
      "Epoch 00010: loss improved from 1.33471 to 1.33364, saving model to ./transfer_pol2_emo6/entire_corpus/10-1.334-0.511-1.313-0.515.hdf5\n",
      "Epoch 11/20\n",
      "375128/375128 [==============================] - 348s 927us/step - loss: 1.3337 - acc: 0.5108 - val_loss: 1.3131 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00011: loss did not improve from 1.33364\n",
      "Epoch 12/20\n",
      "375128/375128 [==============================] - 345s 919us/step - loss: 1.3330 - acc: 0.5110 - val_loss: 1.3130 - val_acc: 0.5155\n",
      "\n",
      "Epoch 00012: loss improved from 1.33364 to 1.33304, saving model to ./transfer_pol2_emo6/entire_corpus/12-1.333-0.511-1.313-0.515.hdf5\n",
      "Epoch 13/20\n",
      "375128/375128 [==============================] - 344s 918us/step - loss: 1.3300 - acc: 0.5118 - val_loss: 1.3090 - val_acc: 0.5158\n",
      "\n",
      "Epoch 00013: loss improved from 1.33304 to 1.33001, saving model to ./transfer_pol2_emo6/entire_corpus/13-1.330-0.512-1.309-0.516.hdf5\n",
      "Epoch 14/20\n",
      "375128/375128 [==============================] - 350s 933us/step - loss: 1.3284 - acc: 0.5123 - val_loss: 1.3091 - val_acc: 0.5159\n",
      "\n",
      "Epoch 00014: loss improved from 1.33001 to 1.32843, saving model to ./transfer_pol2_emo6/entire_corpus/14-1.328-0.512-1.309-0.516.hdf5\n",
      "Epoch 15/20\n",
      "375128/375128 [==============================] - 341s 909us/step - loss: 1.3279 - acc: 0.5115 - val_loss: 1.3081 - val_acc: 0.5161\n",
      "\n",
      "Epoch 00015: loss improved from 1.32843 to 1.32789, saving model to ./transfer_pol2_emo6/entire_corpus/15-1.328-0.512-1.308-0.516.hdf5\n",
      "Epoch 16/20\n",
      "375128/375128 [==============================] - 345s 919us/step - loss: 1.3282 - acc: 0.5116 - val_loss: 1.3071 - val_acc: 0.5167\n",
      "\n",
      "Epoch 00016: loss did not improve from 1.32789\n",
      "Epoch 17/20\n",
      "375128/375128 [==============================] - 355s 945us/step - loss: 1.3279 - acc: 0.5119 - val_loss: 1.3071 - val_acc: 0.5176\n",
      "\n",
      "Epoch 00017: loss did not improve from 1.32789\n",
      "Epoch 18/20\n",
      "375128/375128 [==============================] - 352s 938us/step - loss: 1.3271 - acc: 0.5123 - val_loss: 1.3080 - val_acc: 0.5164\n",
      "\n",
      "Epoch 00018: loss improved from 1.32789 to 1.32708, saving model to ./transfer_pol2_emo6/entire_corpus/18-1.327-0.512-1.308-0.516.hdf5\n",
      "Epoch 19/20\n",
      "375128/375128 [==============================] - 355s 946us/step - loss: 1.3264 - acc: 0.5125 - val_loss: 1.3062 - val_acc: 0.5168\n",
      "\n",
      "Epoch 00019: loss improved from 1.32708 to 1.32643, saving model to ./transfer_pol2_emo6/entire_corpus/19-1.326-0.512-1.306-0.517.hdf5\n",
      "Epoch 20/20\n",
      "375128/375128 [==============================] - 353s 941us/step - loss: 1.3255 - acc: 0.5125 - val_loss: 1.3066 - val_acc: 0.5170\n",
      "\n",
      "Epoch 00020: loss improved from 1.32643 to 1.32551, saving model to ./transfer_pol2_emo6/entire_corpus/20-1.326-0.513-1.307-0.517.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53bdf907f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "transfer_model.fit(tweets_emo_6, labels_emo_6, batch_size=128, epochs=20, validation_split=0.1, shuffle=True, callbacks=[checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transfer learning - (emotion_6 to emotion_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load model (positive/negative CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./transfer_pol2_emo6/entire_corpus/20-1.326-0.513-1.307-0.517.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "PATH_MODEL_EMO_6 = './transfer_pol2_emo6/entire_corpus/20-1.326-0.513-1.307-0.517.hdf5'\n",
    "transfer_model = load_model(PATH_MODEL_EMO_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 200)           18000200  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 38, 600)           360600    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 36, 300)           540300    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 34, 150)           135150    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 32, 75)            33825     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               1440600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 2406      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 20,753,481\n",
      "Trainable params: 242,806\n",
      "Non-trainable params: 20,510,675\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut last layers\n",
    "transfer_model.pop()\n",
    "transfer_model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers\n",
    "for layer in transfer_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add news layers\n",
    "transfer_model.add(Dense(350, name='dense_4'))\n",
    "transfer_model.add(Activation('relu', name='activation_4'))\n",
    "\n",
    "transfer_model.add(Dense(4, name='dense_5'))\n",
    "transfer_model.add(Activation('softmax', name='activation_5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Fine tunning and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "transfer_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 200)           18000200  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 38, 600)           360600    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 36, 300)           540300    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 34, 150)           135150    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 32, 75)            33825     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               1440600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 350)               140350    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 1404      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,892,829\n",
      "Trainable params: 141,754\n",
      "Non-trainable params: 20,751,075\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./transfer_emo6_emo4/entire_corpus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "filepath = \"./transfer_emo6_emo4/entire_corpus/{epoch:02d}-{loss:0.3f}-{acc:0.3f}-{val_loss:0.3f}-{val_acc:0.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27144 samples, validate on 3016 samples\n",
      "Epoch 1/20\n",
      "27144/27144 [==============================] - 20s 720us/step - loss: 0.9733 - acc: 0.5805 - val_loss: 0.9564 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.97330, saving model to ./transfer_emo6_emo4/entire_corpus/01-0.973-0.581-0.956-0.588.hdf5\n",
      "Epoch 2/20\n",
      "27144/27144 [==============================] - 21s 768us/step - loss: 0.9516 - acc: 0.5875 - val_loss: 0.9586 - val_acc: 0.5796\n",
      "\n",
      "Epoch 00002: loss improved from 0.97330 to 0.95161, saving model to ./transfer_emo6_emo4/entire_corpus/02-0.952-0.587-0.959-0.580.hdf5\n",
      "Epoch 3/20\n",
      "27144/27144 [==============================] - 22s 802us/step - loss: 0.9443 - acc: 0.5912 - val_loss: 0.9460 - val_acc: 0.5948\n",
      "\n",
      "Epoch 00003: loss improved from 0.95161 to 0.94434, saving model to ./transfer_emo6_emo4/entire_corpus/03-0.944-0.591-0.946-0.595.hdf5\n",
      "Epoch 4/20\n",
      "27144/27144 [==============================] - 22s 809us/step - loss: 0.9434 - acc: 0.5931 - val_loss: 0.9465 - val_acc: 0.5872\n",
      "\n",
      "Epoch 00004: loss improved from 0.94434 to 0.94340, saving model to ./transfer_emo6_emo4/entire_corpus/04-0.943-0.593-0.946-0.587.hdf5\n",
      "Epoch 5/20\n",
      "27144/27144 [==============================] - 23s 863us/step - loss: 0.9403 - acc: 0.5956 - val_loss: 0.9476 - val_acc: 0.5948\n",
      "\n",
      "Epoch 00005: loss improved from 0.94340 to 0.94033, saving model to ./transfer_emo6_emo4/entire_corpus/05-0.940-0.596-0.948-0.595.hdf5\n",
      "Epoch 6/20\n",
      "27144/27144 [==============================] - 22s 825us/step - loss: 0.9345 - acc: 0.5977 - val_loss: 0.9424 - val_acc: 0.5935\n",
      "\n",
      "Epoch 00006: loss improved from 0.94033 to 0.93449, saving model to ./transfer_emo6_emo4/entire_corpus/06-0.934-0.598-0.942-0.594.hdf5\n",
      "Epoch 7/20\n",
      "27144/27144 [==============================] - 23s 851us/step - loss: 0.9334 - acc: 0.6004 - val_loss: 0.9420 - val_acc: 0.5912\n",
      "\n",
      "Epoch 00007: loss improved from 0.93449 to 0.93336, saving model to ./transfer_emo6_emo4/entire_corpus/07-0.933-0.600-0.942-0.591.hdf5\n",
      "Epoch 8/20\n",
      "27144/27144 [==============================] - 24s 891us/step - loss: 0.9296 - acc: 0.5999 - val_loss: 0.9408 - val_acc: 0.5922\n",
      "\n",
      "Epoch 00008: loss improved from 0.93336 to 0.92960, saving model to ./transfer_emo6_emo4/entire_corpus/08-0.930-0.600-0.941-0.592.hdf5\n",
      "Epoch 9/20\n",
      "27144/27144 [==============================] - 25s 913us/step - loss: 0.9303 - acc: 0.5994 - val_loss: 0.9380 - val_acc: 0.5958\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.92960\n",
      "Epoch 10/20\n",
      "27144/27144 [==============================] - 25s 939us/step - loss: 0.9287 - acc: 0.6012 - val_loss: 0.9388 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00010: loss improved from 0.92960 to 0.92874, saving model to ./transfer_emo6_emo4/entire_corpus/10-0.929-0.601-0.939-0.588.hdf5\n",
      "Epoch 11/20\n",
      "27144/27144 [==============================] - 25s 922us/step - loss: 0.9295 - acc: 0.5980 - val_loss: 0.9407 - val_acc: 0.5875\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.92874\n",
      "Epoch 12/20\n",
      "27144/27144 [==============================] - 25s 924us/step - loss: 0.9256 - acc: 0.6017 - val_loss: 0.9373 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00012: loss improved from 0.92874 to 0.92557, saving model to ./transfer_emo6_emo4/entire_corpus/12-0.926-0.602-0.937-0.592.hdf5\n",
      "Epoch 13/20\n",
      "27144/27144 [==============================] - 24s 886us/step - loss: 0.9297 - acc: 0.5994 - val_loss: 0.9394 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.92557\n",
      "Epoch 14/20\n",
      "27144/27144 [==============================] - 25s 923us/step - loss: 0.9280 - acc: 0.6011 - val_loss: 0.9370 - val_acc: 0.5892\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.92557\n",
      "Epoch 15/20\n",
      "27144/27144 [==============================] - 25s 935us/step - loss: 0.9219 - acc: 0.6029 - val_loss: 0.9368 - val_acc: 0.5932\n",
      "\n",
      "Epoch 00015: loss improved from 0.92557 to 0.92186, saving model to ./transfer_emo6_emo4/entire_corpus/15-0.922-0.603-0.937-0.593.hdf5\n",
      "Epoch 16/20\n",
      "27144/27144 [==============================] - 25s 934us/step - loss: 0.9264 - acc: 0.6027 - val_loss: 0.9399 - val_acc: 0.5928\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.92186\n",
      "Epoch 17/20\n",
      "27144/27144 [==============================] - 27s 996us/step - loss: 0.9225 - acc: 0.6051 - val_loss: 0.9374 - val_acc: 0.5938\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.92186\n",
      "Epoch 18/20\n",
      "27144/27144 [==============================] - 25s 917us/step - loss: 0.9245 - acc: 0.6034 - val_loss: 0.9367 - val_acc: 0.5908\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.92186\n",
      "Epoch 19/20\n",
      "27144/27144 [==============================] - 25s 907us/step - loss: 0.9237 - acc: 0.6052 - val_loss: 0.9357 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.92186\n",
      "Epoch 20/20\n",
      "27144/27144 [==============================] - 24s 896us/step - loss: 0.9210 - acc: 0.6076 - val_loss: 0.9373 - val_acc: 0.5922\n",
      "\n",
      "Epoch 00020: loss improved from 0.92186 to 0.92096, saving model to ./transfer_emo6_emo4/entire_corpus/20-0.921-0.608-0.937-0.592.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53bcef2320>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "transfer_model.fit(tweets_emo_4, labels_emo_4, batch_size=128, epochs=20, validation_split=0.1, shuffle=True, callbacks=[checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 200)           18000200  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 38, 600)           360600    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 36, 300)           540300    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 34, 150)           135150    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 32, 75)            33825     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               1440600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 350)               210350    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 1404      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,722,429\n",
      "Trainable params: 211,754\n",
      "Non-trainable params: 20,510,675\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../dataset/tweets/tweets_emotion_4/tweets_emotions_prediction-processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PROCESSED_FILE = '../dataset/tweets/tweets_emotion_4/tweets_emotions_prediction-processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 2755/2755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_tweets, _ = process_tweets(TEST_PROCESSED_FILE, test_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = pad_sequences(test_tweets, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755/2755 [==============================] - 2s 643us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = transfer_model.predict(test_tweets, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = zip(map(str, range(len(test_tweets))), np.round(predictions[:, 0]).astype(int))\n",
    "utils.save_results_to_csv(results, '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36825687, 0.02165285, 0.00128797, ..., 0.46889895, 0.14677207,\n",
       "       0.01749193], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusions = ['angry', 'sad', 'others', 'happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_predict = [conclusions[np.argmax(predictions[i])] for i in range(len(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../dataset/tweets/tweets_emotion_4/tweets_emotions_prediction.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE_INPUT = '../dataset/tweets/tweets_emotion_4/tweets_emotions_prediction.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_FILE_INPUT, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    test_df[conclusions[i]] = predictions.T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>angry</th>\n",
       "      <th>sad</th>\n",
       "      <th>others</th>\n",
       "      <th>happy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then dont ask me</td>\n",
       "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
       "      <td>IM NOT A GUY FUCK OFF</td>\n",
       "      <td>0.368257</td>\n",
       "      <td>0.049950</td>\n",
       "      <td>0.534507</td>\n",
       "      <td>0.047286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed things  such as??</td>\n",
       "      <td>the things you do.</td>\n",
       "      <td>Have you seen minions??</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.754616</td>\n",
       "      <td>0.214098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I'm very happy</td>\n",
       "      <td>and I'm happy for you </td>\n",
       "      <td>I will be marry</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.436287</td>\n",
       "      <td>0.561214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Woah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>Brb</td>\n",
       "      <td>0.125436</td>\n",
       "      <td>0.055360</td>\n",
       "      <td>0.559979</td>\n",
       "      <td>0.259225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thooooo</td>\n",
       "      <td>I said soon master.</td>\n",
       "      <td>he is pressuring me</td>\n",
       "      <td>0.306928</td>\n",
       "      <td>0.166277</td>\n",
       "      <td>0.488765</td>\n",
       "      <td>0.038030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    turn1                                       turn2  \\\n",
       "0   0         Then dont ask me  YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND   \n",
       "1   1  Mixed things  such as??                          the things you do.   \n",
       "2   2     Today I'm very happy                     and I'm happy for you    \n",
       "3   3       Woah bring me some                          left it there oops   \n",
       "4   4            it is thooooo                         I said soon master.   \n",
       "\n",
       "                     turn3     angry       sad    others     happy  \n",
       "0    IM NOT A GUY FUCK OFF  0.368257  0.049950  0.534507  0.047286  \n",
       "1  Have you seen minions??  0.021653  0.009634  0.754616  0.214098  \n",
       "2          I will be marry  0.001288  0.001211  0.436287  0.561214  \n",
       "3                      Brb  0.125436  0.055360  0.559979  0.259225  \n",
       "4      he is pressuring me  0.306928  0.166277  0.488765  0.038030  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE_OUTPUT = '../dataset/tweets/tweets_emotion_4/tweets_emotions_prediction_probabilities.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(TEST_FILE_OUTPUT, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
